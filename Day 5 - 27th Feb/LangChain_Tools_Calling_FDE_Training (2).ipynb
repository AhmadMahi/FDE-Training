{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLy6oXJc0atE",
        "outputId": "7bd724a9-d40a-4a75-9caa-c242d87f71ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.2.10\n",
            "Uninstalling langchain-1.2.10:\n",
            "  Successfully uninstalled langchain-1.2.10\n",
            "\u001b[33mWARNING: Skipping langchain-openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y langchain langchain-openai\n",
        "!pip install -q langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "ZakjHzJk0b2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Evaluates a mathematical expression.\n",
        "    Example: \"2 + 2 * 10\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return str(result)\n",
        "    except Exception:\n",
        "        return \"Invalid mathematical expression.\""
      ],
      "metadata": {
        "id": "mMZ675pU0le8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_order_status(order_id: str) -> str:\n",
        "    \"\"\"\n",
        "    Returns order status for a given order ID.\n",
        "    \"\"\"\n",
        "    fake_database = {\n",
        "        \"ORD123\": \"Shipped\",\n",
        "        \"ORD456\": \"Processing\",\n",
        "        \"ORD789\": \"Delivered\"\n",
        "    }\n",
        "    return fake_database.get(order_id, \"Order not found.\")"
      ],
      "metadata": {
        "id": "B4WRySZA0sHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Give me a short definition of DNN.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urp_HMzI0zcS",
        "outputId": "ee0c5ab0-3ab2-43a9-a6b7-765ecb927af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Deep Neural Network (DNN) is a type of artificial neural network with multiple layers of nodes (neurons) between the input and output layers, allowing it to learn complex patterns and representations from large datasets. DNNs are commonly used in various applications such as image and speech recognition, natural language processing, and more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools = [calculator, get_order_status]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "Kk4wfA4h0tlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is 45 multiplied by 12?\""
      ],
      "metadata": {
        "id": "9PDTMySw0vSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_with_tools.invoke(\n",
        "    [HumanMessage(content=query)]\n",
        ")\n",
        "\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcUoGiZI03vz",
        "outputId": "fa7e1914-7f41-4802-c35d-e78e250532e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 87, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_373a14eb6f', 'id': 'chatcmpl-DDhT3raan1OJl0mC1VKecCAkbzrlX', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c9cd4-e896-7870-bd82-14c835556026-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '45 * 12'}, 'id': 'call_dVK54lKlc9lkCCvAKWmkZZQl', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 87, 'output_tokens': 17, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_with_tools(user_query):\n",
        "    messages = [HumanMessage(content=user_query)]\n",
        "\n",
        "    while True:\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "\n",
        "        # If no tool call â†’ return final answer\n",
        "        if not response.tool_calls:\n",
        "            return response.content\n",
        "\n",
        "        messages.append(response)\n",
        "\n",
        "        # Execute each tool call\n",
        "        for tool_call in response.tool_calls:\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool_args = tool_call[\"args\"]\n",
        "\n",
        "            if tool_name == \"get_order_status\":\n",
        "                tool_result = get_order_status.invoke(tool_args)\n",
        "\n",
        "            if tool_name == \"calculator\":\n",
        "                tool_result = calculator.invoke(tool_args)\n",
        "\n",
        "                messages.append(\n",
        "                    ToolMessage(\n",
        "                        content=tool_result,\n",
        "                        tool_call_id=tool_call[\"id\"]\n",
        "                    )\n",
        "                )"
      ],
      "metadata": {
        "id": "G3DVwjmm1GBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = run_with_tools(\"What is 45 multiplied by 12?\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZRQ2uBc1kem",
        "outputId": "9de8713f-4a78-4627-d59e-4004cb26dbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45 multiplied by 12 is 540.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Auto Tool Selection with LangChain**"
      ],
      "metadata": {
        "id": "1wYvxwzb25ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-openai requests\n",
        "!pip install -q langchain langchain-openai requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D7ZW7yM1mw3",
        "outputId": "2ff320f8-601b-4d06-b763-bcce23a5ac75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.2.10\n",
            "Uninstalling langchain-1.2.10:\n",
            "  Successfully uninstalled langchain-1.2.10\n",
            "Found existing installation: langchain-openai 1.1.10\n",
            "Uninstalling langchain-openai-1.1.10:\n",
            "  Successfully uninstalled langchain-openai-1.1.10\n",
            "Found existing installation: requests 2.32.4\n",
            "Uninstalling requests-2.32.4:\n",
            "  Successfully uninstalled requests-2.32.4\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "XjcaN7od4FWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPENWEATHER_API_KEY = \"209688131a0268b51c101f612dca54ca\""
      ],
      "metadata": {
        "id": "XggNKKBG2932"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get current weather for a given city.\"\"\"\n",
        "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
        "    response = requests.get(url).json()\n",
        "\n",
        "    if response.get(\"cod\") != 200:\n",
        "        return \"City not found.\"\n",
        "\n",
        "    temp = response[\"main\"][\"temp\"]\n",
        "    description = response[\"weather\"][0][\"description\"]\n",
        "    return f\"The current temperature in {city} is {temp}Â°C with {description}.\""
      ],
      "metadata": {
        "id": "Dq5v1-aa3pG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        return str(eval(expression))\n",
        "    except:\n",
        "        return \"Invalid expression.\""
      ],
      "metadata": {
        "id": "vVq-LlzF3qpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def calculate_interest(principal: float, rate: float, years: float) -> str:\n",
        "    \"\"\"Calculate simple interest given principal, annual rate (%), and years.\"\"\"\n",
        "    interest = (principal * rate * years) / 100\n",
        "    total = principal + interest\n",
        "    return f\"Interest: {interest}, Total amount: {total}\""
      ],
      "metadata": {
        "id": "1GjJ-sGh3sK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def get_current_date() -> str:\n",
        "    \"\"\"Returns today's date.\"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d\")"
      ],
      "metadata": {
        "id": "4q5Z1wlo3t9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    get_weather,\n",
        "    calculator,\n",
        "    calculate_interest,\n",
        "    get_current_date\n",
        "]\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "wWPo_x0E3vgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(user_query):\n",
        "    messages = [HumanMessage(content=user_query)]\n",
        "\n",
        "    while True:\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "\n",
        "        # If no tool call, return answer\n",
        "        if not response.tool_calls:\n",
        "            return response.content\n",
        "\n",
        "        messages.append(response)\n",
        "\n",
        "        # Execute tool calls\n",
        "        for tool_call in response.tool_calls:\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool_args = tool_call[\"args\"]\n",
        "\n",
        "            tool_map = {\n",
        "                \"get_weather\": get_weather,\n",
        "                \"calculator\": calculator,\n",
        "                \"calculate_interest\": calculate_interest,\n",
        "                \"get_current_date\": get_current_date\n",
        "            }\n",
        "\n",
        "            tool_result = tool_map[tool_name].invoke(tool_args)\n",
        "\n",
        "            messages.append(\n",
        "                ToolMessage(\n",
        "                    content=tool_result,\n",
        "                    tool_call_id=tool_call[\"id\"]\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "GErXDYj-3xNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"What is the weather in Mumbai?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DGtRTnFw3y-c",
        "outputId": "0d675a4c-1265-4bc0-d5da-3719a8ce1275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current temperature in Mumbai is 23.99Â°C with haze.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"What is 245 multiplied by 18?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PuT3kTvQ307k",
        "outputId": "5d6368af-15fb-41fc-e091-6540ffcdf887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'245 multiplied by 18 is 4410.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"Calculate interest for 100000 at 7% for 3 years\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rIWKP68r34Em",
        "outputId": "feb8c05c-4bde-47c3-af68-2e33e41c26c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The interest for a principal of $100,000 at an annual rate of 7% for 3 years is $21,000. The total amount after 3 years will be $121,000.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"What is today's date?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hShTLRck354-",
        "outputId": "36bf52bb-ecc6-4ae4-92f3-656e831fc333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Today's date is February 27, 2026.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"What is Machine Learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "XqdNyCE438YP",
        "outputId": "6ee8b439-bc0f-4ef1-983b-ec41851b3692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Machine Learning (ML) is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Instead of being programmed to perform a task, machine learning systems learn from data, identify patterns, and make decisions based on that data.\\n\\nKey concepts in machine learning include:\\n\\n1. **Data**: The foundation of machine learning. Models are trained on large datasets to learn patterns and make predictions.\\n\\n2. **Algorithms**: These are the mathematical procedures that process the data. Common algorithms include decision trees, neural networks, support vector machines, and clustering algorithms.\\n\\n3. **Training**: The process of feeding data into a machine learning model to help it learn. This involves adjusting the model's parameters to minimize errors in its predictions.\\n\\n4. **Testing and Validation**: After training, the model is tested on unseen data to evaluate its performance. This helps ensure that the model generalizes well to new data.\\n\\n5. **Supervised Learning**: A type of machine learning where the model is trained on labeled data, meaning the input data is paired with the correct output.\\n\\n6. **Unsupervised Learning**: In this approach, the model is trained on data without labeled responses, and it tries to find patterns or groupings in the data.\\n\\n7. **Reinforcement Learning**: A type of learning where an agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward.\\n\\nMachine learning is widely used in various applications, including image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles, among others.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SERPER_API_KEY = \"c1da5517f1e790b5ae275a6fc44e2a47bf6fa618\""
      ],
      "metadata": {
        "id": "ksQqk4Ep4WKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def web_search(query: str) -> str:\n",
        "    \"\"\"Search the web for up-to-date information using Google search.\"\"\"\n",
        "\n",
        "    url = \"https://google.serper.dev/search\"\n",
        "\n",
        "    headers = {\n",
        "        \"X-API-KEY\": SERPER_API_KEY,\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "\n",
        "    payload = {\n",
        "        \"q\": query,\n",
        "        \"num\": 5\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload).json()\n",
        "\n",
        "    if \"organic\" not in response:\n",
        "        return \"No results found.\"\n",
        "\n",
        "    results = []\n",
        "    for item in response[\"organic\"][:3]:\n",
        "        title = item.get(\"title\", \"\")\n",
        "        snippet = item.get(\"snippet\", \"\")\n",
        "        link = item.get(\"link\", \"\")\n",
        "        results.append(f\"{title}\\n{snippet}\\n{link}\\n\")\n",
        "\n",
        "    return \"\\n\".join(results)"
      ],
      "metadata": {
        "id": "-WWJ9CfS4s5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(user_query):\n",
        "    messages = [HumanMessage(content=user_query)]\n",
        "\n",
        "    while True:\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "\n",
        "        # If no tool call â†’ return final answer\n",
        "        if not response.tool_calls:\n",
        "            return response.content\n",
        "\n",
        "        messages.append(response)\n",
        "\n",
        "        # Execute tool calls\n",
        "        for tool_call in response.tool_calls:\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool_args = tool_call[\"args\"]\n",
        "\n",
        "            # Updated tool map (added web_search)\n",
        "            tool_map = {\n",
        "                \"get_weather\": get_weather,\n",
        "                \"calculator\": calculator,\n",
        "                \"calculate_interest\": calculate_interest,\n",
        "                \"get_current_date\": get_current_date,\n",
        "                \"web_search\": web_search   # <-- Added here\n",
        "            }\n",
        "\n",
        "            # Safety check (recommended)\n",
        "            if tool_name not in tool_map:\n",
        "                raise ValueError(f\"Unknown tool requested: {tool_name}\")\n",
        "\n",
        "            tool_result = tool_map[tool_name].invoke(tool_args)\n",
        "\n",
        "            messages.append(\n",
        "                ToolMessage(\n",
        "                    content=tool_result,\n",
        "                    tool_call_id=tool_call[\"id\"]\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "UKf_Uu_b4ukT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"Who won the most recent ICC Cricket World Cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_25XI3F34w_8",
        "outputId": "1ed1b1ce-d453-4f1e-8830-d12226889a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Australia won the most recent ICC Cricket World Cup, which took place on November 19, 2023. They defeated India by 6 wickets in the final match held at the Narendra Modi Stadium in Ahmedabad.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(user_query):\n",
        "    messages = [HumanMessage(content=user_query)]\n",
        "\n",
        "    print(f\"\\nðŸ§‘ User: {user_query}\")\n",
        "\n",
        "    while True:\n",
        "        response = llm_with_tools.invoke(messages)\n",
        "\n",
        "        # âœ… If no tool call â†’ pure LLM response\n",
        "        if not response.tool_calls:\n",
        "            print(\"\\nðŸ¤– Model Response (No tool used)\")\n",
        "            print(response.content)\n",
        "            return response.content\n",
        "\n",
        "        messages.append(response)\n",
        "\n",
        "        # Execute tool calls\n",
        "        for tool_call in response.tool_calls:\n",
        "            tool_name = tool_call[\"name\"]\n",
        "            tool_args = tool_call[\"args\"]\n",
        "\n",
        "            print(f\"\\nðŸ”§ Tool Selected: {tool_name}\")\n",
        "            print(f\"ðŸ“¦ Tool Arguments: {tool_args}\")\n",
        "\n",
        "            tool_map = {\n",
        "                \"get_weather\": get_weather,\n",
        "                \"calculator\": calculator,\n",
        "                \"calculate_interest\": calculate_interest,\n",
        "                \"get_current_date\": get_current_date,\n",
        "                \"web_search\": web_search\n",
        "            }\n",
        "\n",
        "            if tool_name not in tool_map:\n",
        "                raise ValueError(f\"Unknown tool requested: {tool_name}\")\n",
        "\n",
        "            tool_result = tool_map[tool_name].invoke(tool_args)\n",
        "\n",
        "            print(f\"ðŸ“¤ Tool Result:\\n{tool_result}\")\n",
        "\n",
        "            messages.append(\n",
        "                ToolMessage(\n",
        "                    content=tool_result,\n",
        "                    tool_call_id=tool_call[\"id\"]\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "UOFyJnuq4ys_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"What is the weather in Mumbai?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "q1uhRKzS5UH7",
        "outputId": "c7f37773-f6ae-4a37-d2e8-a76455dbb254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§‘ User: What is the weather in Mumbai?\n",
            "\n",
            "ðŸ”§ Tool Selected: get_weather\n",
            "ðŸ“¦ Tool Arguments: {'city': 'Mumbai'}\n",
            "ðŸ“¤ Tool Result:\n",
            "The current temperature in Mumbai is 23.99Â°C with haze.\n",
            "\n",
            "ðŸ¤– Model Response (No tool used)\n",
            "The current weather in Mumbai is 23.99Â°C with haze.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current weather in Mumbai is 23.99Â°C with haze.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_agent(\"Explain what machine learning is.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "AG-x-svi5Vvd",
        "outputId": "148ebbfc-85ce-4ade-fadf-65cdbfa2abc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ§‘ User: Explain what machine learning is.\n",
            "\n",
            "ðŸ¤– Model Response (No tool used)\n",
            "Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Instead of being programmed to perform a task, machine learning systems learn from data, identifying patterns and making decisions based on that data.\n",
            "\n",
            "Here are some key concepts related to machine learning:\n",
            "\n",
            "1. **Data**: Machine learning relies on large amounts of data to train models. This data can be structured (like databases) or unstructured (like images or text).\n",
            "\n",
            "2. **Algorithms**: These are the mathematical models that process the data. Common algorithms include decision trees, neural networks, support vector machines, and clustering algorithms.\n",
            "\n",
            "3. **Training**: The process of feeding data into a machine learning model so that it can learn from it. During training, the model adjusts its parameters to minimize errors in its predictions.\n",
            "\n",
            "4. **Testing and Validation**: After training, the model is tested on a separate dataset to evaluate its performance. This helps ensure that the model generalizes well to new, unseen data.\n",
            "\n",
            "5. **Supervised Learning**: A type of machine learning where the model is trained on labeled data, meaning the input data is paired with the correct output. Examples include classification and regression tasks.\n",
            "\n",
            "6. **Unsupervised Learning**: In this approach, the model is trained on data without labeled responses. It tries to find patterns or groupings in the data. Examples include clustering and dimensionality reduction.\n",
            "\n",
            "7. **Reinforcement Learning**: A type of learning where an agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward.\n",
            "\n",
            "Machine learning is widely used in various applications, including image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles, among others. Its ability to improve over time as it is exposed to more data makes it a powerful tool in many fields.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Machine learning is a subset of artificial intelligence (AI) that focuses on the development of algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Instead of being programmed to perform a task, machine learning systems learn from data, identifying patterns and making decisions based on that data.\\n\\nHere are some key concepts related to machine learning:\\n\\n1. **Data**: Machine learning relies on large amounts of data to train models. This data can be structured (like databases) or unstructured (like images or text).\\n\\n2. **Algorithms**: These are the mathematical models that process the data. Common algorithms include decision trees, neural networks, support vector machines, and clustering algorithms.\\n\\n3. **Training**: The process of feeding data into a machine learning model so that it can learn from it. During training, the model adjusts its parameters to minimize errors in its predictions.\\n\\n4. **Testing and Validation**: After training, the model is tested on a separate dataset to evaluate its performance. This helps ensure that the model generalizes well to new, unseen data.\\n\\n5. **Supervised Learning**: A type of machine learning where the model is trained on labeled data, meaning the input data is paired with the correct output. Examples include classification and regression tasks.\\n\\n6. **Unsupervised Learning**: In this approach, the model is trained on data without labeled responses. It tries to find patterns or groupings in the data. Examples include clustering and dimensionality reduction.\\n\\n7. **Reinforcement Learning**: A type of learning where an agent learns to make decisions by taking actions in an environment to maximize some notion of cumulative reward.\\n\\nMachine learning is widely used in various applications, including image and speech recognition, natural language processing, recommendation systems, and autonomous vehicles, among others. Its ability to improve over time as it is exposed to more data makes it a powerful tool in many fields.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7kY3KTh5Y8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}